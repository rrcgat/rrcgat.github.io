{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新闻文本分类\n",
    "\n",
    "- 学习链接：https://github.com/datawhalechina/team-learning-nlp/tree/master/NewsTextClassification\n",
    "- 比赛链接：[零基础入门NLP - 新闻文本分类 - 天池](https://tianchi.aliyun.com/competition/entrance/531810/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1\n",
    "\n",
    "https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.6.6406111aIKCSLV&postId=118252\n",
    "\n",
    "任务一主要是理解赛题和数据，并没实际工作量。\n",
    "\n",
    "数据下载解压之后，得到三个文件：\n",
    "\n",
    "```\n",
    "test_a.csv               211M\n",
    "test_a_sample_submit.csv 98K\n",
    "train_set.csv            840M\n",
    "```\n",
    "\n",
    "训练集和测试集都对字符进行了匿名处理，所以不用分词这一步。\n",
    "\n",
    "训练数据有 20w 条，使用 `\\t` 分隔，第一列为标签，第二列为文本。标签有 14 类，其对应关系为：\n",
    "\n",
    "```\n",
    "科技: 0\n",
    "股票: 1\n",
    "体育: 2\n",
    "娱乐: 3\n",
    "时政: 4\n",
    "社会: 5\n",
    "教育: 6\n",
    "财经: 7\n",
    "家居: 8\n",
    "游戏: 9\n",
    "房产: 10\n",
    "时尚: 11\n",
    "彩票: 12\n",
    "星座: 13\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2\n",
    "\n",
    "https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.9.6406111aIKCSLV&postId=118253\n",
    "\n",
    "任务二需要完成以下作业：\n",
    "\n",
    "1. 假设字符 3750，字符 900 和字符 648 是句子的标点符号，请分析赛题每篇新闻平均由多少个句子构成？\n",
    "2. 统计每类新闻中出现次数对多的字符\n",
    "\n",
    "### 文本长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200000.000000\n",
       "mean        907.207110\n",
       "std         996.029036\n",
       "min           2.000000\n",
       "25%         374.000000\n",
       "50%         676.000000\n",
       "75%        1131.000000\n",
       "max       57921.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('data/train_set.csv', sep='\\t')\n",
    "\n",
    "train_df['text_len'] = train_df['text'].apply(lambda x: len(x.split()))\n",
    "train_df['text_len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，平均每篇新闻有 907 个字符，最短的有 2 个字符，最长的有 57921 个字符。\n",
    "\n",
    "### 新闻类别分布\n",
    "\n",
    "统计每类新闻的样本个数。样本分布不平均，最少的只有 908 个，最多的达到了 38918 个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     38918\n",
       "1     36945\n",
       "2     31425\n",
       "3     22133\n",
       "4     15016\n",
       "5     12232\n",
       "6      9985\n",
       "7      8841\n",
       "8      7847\n",
       "9      5878\n",
       "10     4920\n",
       "11     3131\n",
       "12     1821\n",
       "13      908\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "对于问题一，需要把每篇文章的句子按标点符号切分后再计算句子个数，可直接正则模块切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.922815"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_df['sentences'] = train_df['text'].apply(lambda x: len([s for s in re.split(r'\\b(?:3750|900|648)\\b', x) if s]))\n",
    "train_df['sentences'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，每篇新闻平均有 79 个句子。\n",
    "\n",
    "### Q2\n",
    "\n",
    "问题二需要先根据新闻类别分类后再统一数据，这里使用到了 `loc` 对列数据进行筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新闻类别 0 出现最多的字符为 3750，共出现 1267331 次\n",
      "新闻类别 1 出现最多的字符为 3750，共出现 1200686 次\n",
      "新闻类别 2 出现最多的字符为 3750，共出现 1458331 次\n",
      "新闻类别 3 出现最多的字符为 3750，共出现 774668 次\n",
      "新闻类别 4 出现最多的字符为 3750，共出现 360839 次\n",
      "新闻类别 5 出现最多的字符为 3750，共出现 715740 次\n",
      "新闻类别 6 出现最多的字符为 3750，共出现 469540 次\n",
      "新闻类别 7 出现最多的字符为 3750，共出现 428638 次\n",
      "新闻类别 8 出现最多的字符为 3750，共出现 242367 次\n",
      "新闻类别 9 出现最多的字符为 3750，共出现 178783 次\n",
      "新闻类别 10 出现最多的字符为 3750，共出现 180259 次\n",
      "新闻类别 11 出现最多的字符为 3750，共出现 83834 次\n",
      "新闻类别 12 出现最多的字符为 3750，共出现 87412 次\n",
      "新闻类别 13 出现最多的字符为 3750，共出现 33796 次\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for label in range(14):\n",
    "    c = Counter()\n",
    "    df = train_df['text'].loc[train_df['label']==label].apply(lambda x: x.split())\n",
    "    for news in df:\n",
    "        c.update(Counter(news))\n",
    "    print('新闻类别 {} 出现最多的字符为 {}，共出现 {} 次'.format(label, *c.most_common(1)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
