{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import jieba\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "home = os.path.expanduser('~')\n",
    "\n",
    "raw_text_path = f'{home}/Documents/novel_data/raw/盘龙.txt'\n",
    "\n",
    "process_text_path = f'{home}/Documents/novel_data/盘龙_cut.txt'\n",
    "\n",
    "\n",
    "stop_words_path = f'{home}/Documents/novel_data/stop_words.txt'\n",
    "\n",
    "stop_words = [w for w in load_stop_words() if re.match(r'\\w', w)]\n",
    "\n",
    "\n",
    "def load_stop_words():\n",
    "    with open(stop_words_path, encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "\n",
    "def remove_stop_words(words):\n",
    "    return [w for w in words if w not in stop_words and w.strip()]\n",
    "\n",
    "\n",
    "def remove_title(text):\n",
    "    return re.sub('^第.*?章 .*\\n', '', text)\n",
    "\n",
    "    \n",
    "def remove_special_sym(text):\n",
    "    return re.sub('[^\\n^A-Z^a-z^\\u4e00-\\u9fa5]', ' ', text)\n",
    "\n",
    "\n",
    "def remove_redundancy_space(text):\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return re.sub('\\n+', '\\n', text)\n",
    "\n",
    "\n",
    "def pre_process(text):\n",
    "    text = remove_title(text)\n",
    "    text = remove_special_sym(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def word2vec_from_file(path=process_text_path):\n",
    "    sentences = word2vec.LineSentence(path)\n",
    "    model = word2vec.Word2Vec(sentences,\n",
    "                              hs=1,\n",
    "                              min_count=1,\n",
    "                              window=6,\n",
    "                              size=100)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 01:54:48,770 : INFO : collecting all words and their counts\n",
      "2020-07-07 01:54:48,772 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-07-07 01:54:48,923 : INFO : PROGRESS: at sentence #10000, processed 249233 words, keeping 25488 word types\n",
      "2020-07-07 01:54:49,059 : INFO : PROGRESS: at sentence #20000, processed 470202 words, keeping 37556 word types\n",
      "2020-07-07 01:54:49,210 : INFO : PROGRESS: at sentence #30000, processed 706284 words, keeping 48276 word types\n",
      "2020-07-07 01:54:49,357 : INFO : PROGRESS: at sentence #40000, processed 939725 words, keeping 56533 word types\n",
      "2020-07-07 01:54:49,504 : INFO : PROGRESS: at sentence #50000, processed 1163244 words, keeping 64080 word types\n",
      "2020-07-07 01:54:49,648 : INFO : PROGRESS: at sentence #60000, processed 1389487 words, keeping 71271 word types\n",
      "2020-07-07 01:54:49,799 : INFO : PROGRESS: at sentence #70000, processed 1635124 words, keeping 78462 word types\n",
      "2020-07-07 01:54:49,857 : INFO : collected 80191 word types from a corpus of 1704954 raw words and 73078 sentences\n",
      "2020-07-07 01:54:49,858 : INFO : Loading a fresh vocabulary\n",
      "2020-07-07 01:54:50,364 : INFO : effective_min_count=1 retains 80191 unique words (100% of original 80191, drops 0)\n",
      "2020-07-07 01:54:50,365 : INFO : effective_min_count=1 leaves 1704954 word corpus (100% of original 1704954, drops 0)\n",
      "2020-07-07 01:54:50,743 : INFO : deleting the raw counts dictionary of 80191 items\n",
      "2020-07-07 01:54:50,745 : INFO : sample=0.001 downsamples 27 most-common words\n",
      "2020-07-07 01:54:50,746 : INFO : downsampling leaves estimated 1319234 word corpus (77.4% of prior 1704954)\n",
      "2020-07-07 01:54:50,856 : INFO : constructing a huffman tree from 80191 words\n",
      "2020-07-07 01:54:54,579 : INFO : built huffman tree with maximum node depth 21\n",
      "2020-07-07 01:54:54,793 : INFO : estimated required memory for 80191 words and 100 dimensions: 152362900 bytes\n",
      "2020-07-07 01:54:54,794 : INFO : resetting layer weights\n",
      "2020-07-07 01:55:23,740 : INFO : training model with 3 workers on 80191 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=6\n",
      "2020-07-07 01:55:24,790 : INFO : EPOCH 1 - PROGRESS: at 16.04% examples, 217869 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:25,846 : INFO : EPOCH 1 - PROGRESS: at 37.22% examples, 236963 words/s, in_qsize 6, out_qsize 0\n",
      "2020-07-07 01:55:26,848 : INFO : EPOCH 1 - PROGRESS: at 55.89% examples, 240443 words/s, in_qsize 4, out_qsize 1\n",
      "2020-07-07 01:55:27,866 : INFO : EPOCH 1 - PROGRESS: at 77.94% examples, 248697 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:28,916 : INFO : EPOCH 1 - PROGRESS: at 98.26% examples, 251869 words/s, in_qsize 3, out_qsize 0\n",
      "2020-07-07 01:55:28,925 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 01:55:28,934 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 01:55:28,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 01:55:28,958 : INFO : EPOCH - 1 : training on 1704954 raw words (1319358 effective words) took 5.2s, 253930 effective words/s\n",
      "2020-07-07 01:55:29,974 : INFO : EPOCH 2 - PROGRESS: at 17.26% examples, 237470 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:30,978 : INFO : EPOCH 2 - PROGRESS: at 38.90% examples, 256860 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:32,001 : INFO : EPOCH 2 - PROGRESS: at 60.24% examples, 262336 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:33,021 : INFO : EPOCH 2 - PROGRESS: at 82.58% examples, 266885 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:33,795 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 01:55:33,834 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 01:55:33,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 01:55:33,838 : INFO : EPOCH - 2 : training on 1704954 raw words (1319285 effective words) took 4.9s, 270816 effective words/s\n",
      "2020-07-07 01:55:34,847 : INFO : EPOCH 3 - PROGRESS: at 19.11% examples, 260576 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:35,858 : INFO : EPOCH 3 - PROGRESS: at 41.20% examples, 271894 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:36,883 : INFO : EPOCH 3 - PROGRESS: at 63.15% examples, 274505 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:37,930 : INFO : EPOCH 3 - PROGRESS: at 84.83% examples, 272203 words/s, in_qsize 6, out_qsize 0\n",
      "2020-07-07 01:55:38,582 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 01:55:38,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 01:55:38,600 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 01:55:38,602 : INFO : EPOCH - 3 : training on 1704954 raw words (1319029 effective words) took 4.8s, 277078 effective words/s\n",
      "2020-07-07 01:55:39,667 : INFO : EPOCH 4 - PROGRESS: at 19.11% examples, 248889 words/s, in_qsize 3, out_qsize 2\n",
      "2020-07-07 01:55:40,667 : INFO : EPOCH 4 - PROGRESS: at 40.63% examples, 263253 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:41,738 : INFO : EPOCH 4 - PROGRESS: at 63.18% examples, 267366 words/s, in_qsize 6, out_qsize 0\n",
      "2020-07-07 01:55:42,747 : INFO : EPOCH 4 - PROGRESS: at 84.78% examples, 269415 words/s, in_qsize 6, out_qsize 0\n",
      "2020-07-07 01:55:43,366 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 01:55:43,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 01:55:43,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 01:55:43,411 : INFO : EPOCH - 4 : training on 1704954 raw words (1319800 effective words) took 4.8s, 275080 effective words/s\n",
      "2020-07-07 01:55:44,436 : INFO : EPOCH 5 - PROGRESS: at 17.31% examples, 234550 words/s, in_qsize 4, out_qsize 1\n",
      "2020-07-07 01:55:45,451 : INFO : EPOCH 5 - PROGRESS: at 39.49% examples, 257869 words/s, in_qsize 6, out_qsize 1\n",
      "2020-07-07 01:55:46,501 : INFO : EPOCH 5 - PROGRESS: at 61.46% examples, 263260 words/s, in_qsize 4, out_qsize 1\n",
      "2020-07-07 01:55:47,510 : INFO : EPOCH 5 - PROGRESS: at 83.69% examples, 268120 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-07 01:55:48,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 01:55:48,262 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 01:55:48,297 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 01:55:48,299 : INFO : EPOCH - 5 : training on 1704954 raw words (1319395 effective words) took 4.9s, 270257 effective words/s\n",
      "2020-07-07 01:55:48,301 : INFO : training on a 8524770 raw words (6596867 effective words) took 24.6s, 268614 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 01:56:45,076 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('柯沃', 0.8462332487106323),\n",
       " ('爷爷', 0.824772298336029),\n",
       " ('克沃', 0.7402173280715942),\n",
       " ('用于', 0.7301793098449707),\n",
       " ('杖上', 0.7089070081710815),\n",
       " ('绿纹', 0.7068555951118469),\n",
       " ('愈早', 0.675171434879303),\n",
       " ('师了', 0.6642724871635437),\n",
       " ('林雷不行', 0.6627496480941772),\n",
       " ('装配', 0.659206748008728)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('柯沃特')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
