[{"content":"在已经有了 Word2Vec、GloVe 和 fastText 等各种词向量工具的时候，静态词向量的不足慢慢显现出来了，那就是不能解决一词多义的问题。\n之后出现的 ELMo、GPT 和 BERT 等模型较好地解决了这个问题。\nELMo ELMo 全称 Embeddings from Language Models，采用两层双向 LSTM 对词嵌入进行训练。\n训练过程可分为两步，第一步是对原始数据进行预训练产生词嵌入，\n第二步是将这些词嵌入作为输入，使用两层双向 LSTM 进行训练。\n第一步是预训练，训练出来的词嵌入依旧是静态的。\n第二步使用 LSTM 训练，单向的 LSTM 是由前面的信息预测后面的，\n而双向 LSTM 可以捕捉双向语义，然后进行预测。\n在使用时，输入的不再是单独的单词，而是将单词的上下文加上，一起输入，\n然后动态地计算得到单词对应的词向量。\n更多请参考论文 Deep contextualized word representations。\nLSTM LSTM（Long short-term memory）是 RNN（Recurrent neural network，循环神经网络） 算法中的一种，\n它能在处理数据的时候记住之前的隐藏状态。\n在 ELMo 中的 LSTM 的神经元的输入和输出都有两个，\n额外的输入输出分别是上一神经元的隐藏状态和当前的隐藏状态。\nGPT GPT（Generative Pre-Training）基于 Transformer 模型（只使用多个 Decoder 层），\n首先通过对无标注的原始数据进行训练，然后针对标注数据进行 fine-tuning（微调）。\n了解不深，还没时间细看，可看论文 Improving Language Understanding by Generative Pre-Training。\nBRET BRET（Bidirectional Encoder Representations from Transformers）基于 Transformer 和注意力机制（Attention）训练得到，\n相比于 GPT，BERT 采用了 Transformer Encoder，并对位置进行了编码。\n与传统的 RNN（如 LSTM）不同，Transformer 模型可同时处理所有元素。在其 Encoder-Decoder 结构中，\n数据进入 Encoder 前会经过 Attention 模块，最后由 Decoder 进行输出。\n注意力机制就是让模型专注于合适的语境，在训练到某个词时，注意力机制能注意到跟当前单词更相关的单词。\n有时间看下相关论文：\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nAttention Is All You Need\n参考 更多信息请参考：\nBiLSTM 介绍及代码实现\nNLP详细教程：手把手教你用ELMo模型提取文本特征（附代码\u0026amp;论文）\nThe Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)\nWhat is a Transformer?\nDeconstructing BERT, Part 2: Visualizing the Inner Workings of Attention\n","description":"","id":0,"section":"posts","tags":["nlp"],"title":"ELMo, GPT and BERT","uri":"http://rrcgat.github.io/en/posts/elmo-gpt-bert/"},{"content":"fastText 是用于构建词向量和文本分类的工具。它基于 subword 构建词向量，\n计算过程类似于 Word2Vec 的 CBOW 模型，使用 hashing trick 进行优化（降维）。\nSubword Subword 是比单词更小的元素，他们的基本单元可能是单个的字符，\n也可能是完整的单词。Subword model 是介于 Character level 和 Word level 的模型，\n使用 BPE 或 SentencePiece 算法来选择 subword。\n在此之前的 Word2Vec 和 GloVe 都是基于 Word level 的，即以单词为基本单位。\n其中一个问题是对不在词汇表中的单词（OOV, Out-of-Vocabulary）处理得不是很好，\n于是想到将字符作为基本单元，基于 Character level 的模型。\nCharacter level model Character level 模型与 Word level 的模型类似，但这里的输入不是单词，\n而是单个的字符，输出对应的是 Character embeddings。\n但把单词换成字符带来的是数据量的增加，且数据更加稀疏。\n于是便有了这篇论文 Fully Character-Level Neural Machine Translation without Explicit Segmentation，\n使用 Convolution、Max Pooling 和 Highway layer 来解决这个问题。\nConvolution 即卷积，通过两个函数生成第三个函数。如何通俗易懂地解释卷积？\n关于 Max Pooling: 池化。\n关于 Highway layer: Highway Networks\n这几个都是降维打击的手段，公式跟原理就不班门弄斧了，初学理解不深。\nBPE BPE（Byte Pair Encoding），即字节对编码，是一种数据压缩形式。\n它将数据中常出现的连续字节数据进行替换，重建原始数据。\n假设在字典中，我们有 low: 5, lower: 2, newest: 6, widest: 3，单词后面是对应出现的次数，\n词汇表中就有 l, o, w, e, r, n, w, s, t, i, d，出现频率最高的 n-gram pair 是 (e, s)，\n于是 e 和 s 作为一个整体 es 合并到词汇表中。重复该步骤直至给定的目标。\n最终得到的就是编码后的数据。\nn-gram 是文本或语音序列中 n 个元素的连续序列。\nWordPiece WordPiece 是 BPE 的变种，与 BPE 类似，但在选取 pair 时，不是选频率最高的，而是选似然值最大的。\n 即选取新的 n-gram 时都是选择使得 perplexity 减少最多的 n-gram。\n SentencePiece SentencePiece 将单词之间的空白也当做标记，可直接处理句子。\nHybrid Model 除了 Subword Model，还有一种思路就是通常情况下我们使用 Word level model，\n在 OOV 时使用 Character level model。\n参考 CS224N笔记(十二):Subword模型\n3 subword algorithms help to improve your NLP model performance\n","description":"","id":1,"section":"posts","tags":["nlp"],"title":"fastText","uri":"http://rrcgat.github.io/en/posts/fasttext/"},{"content":"在了解 GloVe 之前，先介绍一下 Count based 模型。\n相比 Direct prediction，Count based 模型会使用到全局的统计数据，借助共现矩阵（co-occurrence matrix）实现上下文表示单词。有两种形式的共现矩阵：基于全文和基于窗口的。这里以基于窗口的经典例子举例。\n假设语料库中有以下句子：\n I like deep learning. I like NLP. I enjoy flying  当窗口长度为 1（一般是 5-10）且对称（不受左右内容影响）时，得到以下共现矩阵：\n为了解决词汇量增加带来的高维开销，其中一个方法是 SVD（奇异值分解），通过将高维矩阵 $X$ 分解为 ${U} {D} {V}^{\\top}$ 形式。\nGlove Glove 全称 Global Vectors for Word Representation。与 Word2Vec 类似，GloVe 是一个基于全局词频统计的词向量工具，同样可以通过向量间的运算得出词与词间的联系。\n假设在矩阵 $X$ 中，$X_{ij}$ 表示单词 $j$ 出现在单词 $i$ 上下文中的次数，$X_{i} = \\sum_{k}X_{ik}$，即所有出现在单词 $i$ 上下文的次数，$P_{ij} = P(j|i) = X_{ij} / X{i}$。\n看下这个例子：\nCrucial insight: Ratios of co-occurrence probabilities can encode meaning components\n\n词与词之间的相关性不是直接用概率来表示，而是通过概率的比间接表示。\n最终给出的损失函数是：\n$$J=\\sum_{i, j=1}^{V} f\\left(X_{i j}\\right)\\left(w_{i}^{T} \\tilde{w}_{j}+b_{i}+\\tilde{b}_{j}-\\log X_{i j}\\right)^{2}$$\n注意到：\n$$w_{i} \\cdot w_{j}=\\log P(i \\mid j)$$\n向量 $w_{i}$ 和 $w_{j}$ 是需要最终求解的。\n函数 f 是权重函数，作用是让常一起出现的单词的权重大于少一起出现的单词，并且权重不能过大，没一起出现的，权重为 0。\n$\\tilde{w}$ 表示上下文向量。\n损失函数的具体推导过程需要看下论文，等理解了再记录下。\n参考 GloVe 详解\n","description":"","id":2,"section":"posts","tags":["nlp"],"title":"GloVe","uri":"http://rrcgat.github.io/en/posts/glove/"},{"content":"NLP，全称 Natural language processing，中文译为「自然语言处理」， 主要的研究对象是自然语言。\n计算机中如何表示词语? 要让计算机理解自然语言，首先面临的一个问题是，计算机中如何表示自然语言中独立运用的最小的单位——词？\n第一个出场的 WordNet 是由专家编写的英语词典，里面包含了词与词之间的联系。缺点很明显，比如不够精确、新词无法处理等等。\n离散符号 传统 NLP 中，使用离散的方式表示单词，比如 one-hot 向量。one-hot 向量的维数等于词汇表中词的个数，每个词在向量中特定的位置为 1，其他位置均为 0，如：\n$$\\text{motel = [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]}$$\n$$\\text{hotel = [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]}$$\n但 one-hot 向量无法反映词与词之间的联系，而使用 WordNet 表示词与词的联系，又引入了 WordNet 的缺点。另一个问题是词汇表的大小直接影响 one-hot 向量的维数，词汇表太大，这种方式基本不可行了。\n分布式表示  Distributional semantics: A world\u0026rsquo;s meaning is given by the worlds that frequently appear close-by.\n 分布式语义的思想是，一个词的意思是由这个词的上下文决定的。由此引入了词向量，其自身就保存了自身的含义及词与词之间的联系。\n词向量，英文 Word vectors(sometimes called word embeddings or word representations)，又称词嵌入。\nWord2Vec Word2Vec 用于将单词转为词向量。它的大致思想是，在一个大的语料库中，每个词都有充足的上下文。对于中心词 $c$ 和上下文 $o$，我们使用 $c$ 和 $o$ 对应的词向量相似度来计算给定 $c$ 时 $o$ 的概率 $P(o|c)$，然后通过调整词向量来最大化 $P(o|c)$。\n在词汇表 $v$ 中，固定窗口大小为 $m$，对于每个位置 $t = 1, \\cdots , T$ 和中心词 $w_{j}$，预测上下文。于是我们有了似然函数 $L(\\theta)$：\n$$\nL(\\theta) =\n\\prod_{t=1}^{T}\n\\prod_{{-m \\le j \\le m} \\atop {j \\neq 0}}\nP \\left(w_{t+j} | w_{t}; \\theta \\right)\n$$\n在似然函数中，$\\theta$ 表示所有需要优化的参数。优化 $\\theta$ 即最大化似然函数，但我们使用负对数似然函数 $J(\\theta)$ 来作为目标函数（object function, sometimes called cost or loss function），最小化负对数似然函数等价于最大化似然函数。\n$$\n\\begin{aligned}\nJ(\\theta) \u0026amp;= -\\frac{1}{T} \\log L(\\theta) \\\n\u0026amp;= -\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\leq j \\leq m \\atop j \\neq 0} \\log P\\left(w_{t+j} | w_{t} ; \\theta\\right)\n\\end{aligned}\n$$\n那么怎么计算 $P \\left(w_{t+j} | w_{t}; \\theta \\right)$ 呢？\n假设对于单词 $w$，$v_{w}$ 表示 $w$ 是中心词，$u_{w}$ 表示 $w$ 是上下文词。那么对于中心词 $c$ 和上下文 $o$，有：\n$$\nP(o | c)=\\frac{\\exp \\left(u_{o}^{T} v_{c}\\right)}{\\sum_{w \\in V} \\exp \\left(u_{w}^{T} v_{c}\\right)}\n$$\n这里使用了 softmax 函数，又称归一化指数函数：\n$$\nsoftmax(x_{i}) = \\frac{exp(x_{i})}{\\sum_{j=1}^{n} exp(x_{j})} = p_{i}\n$$\n它的作用是将 $P(o | c)$ 映射到区间 $(0, 1)$ 中。\n一些黑盒 如果对概率论等相关知识不熟悉，那么上面的一些概念完全就是黑盒。\n似然函数 似然与概率都指某种可能性，但有所不同。概率的可能性是指在给出某个参数时，求产生某个结果的可能性。而似然是在某个结果已产生的时候，求某个参数的可能性。\n目标函数 目标函数即最终需要优化的函数，损失函数或代价函数以最小化函数为优化方向。\n其他 还有未谈及的词袋模型（CBOW）、Skip-Gram 模型、哈夫曼编码、梯度下降等等，后续再补充。\n参考  CS224n - Introduction and Word Vectors Datawhale 第 12 期组队学习 如何理解似然函数? Word2vec 之公式推导笔记  ","description":"","id":3,"section":"posts","tags":["nlp","word2vec"],"title":"词的表示-Word2Vec","uri":"http://rrcgat.github.io/en/posts/cs224n-1-word2vec/"},{"content":"相比于 Python 项目简单清晰的目录结构，Common Lisp 的项目结构要复杂不少，尤其是大型项目。但当你知道每个文件/目录的作用时，会发现这目录结构也不复杂。\n以 Postmodern 项目为例，看看实际项目是怎样组织代码的。\n该项目目录结构如下：\n├── cl-postgres/... ├── cl-postgres.asd ├── postmodern/ │ ├── connect.lisp │ ├── ... │ ├── package.lisp │ └── tests │ ├── ... │ ├── test-package.lisp │ └── tests.lisp ├── postmodern.asd ├── simple-date/... ├── simple-date.asd ├── s-sql/... ├── s-sql.asd └── ... 这里省略了部分目录和文件，但不影响我们解读该目录结构。可以点击链接了解完整的目录结构。\n首先看最外层的文件，这里列出的都是以 .asd 为后缀的文件，这些文件描述了源代码间的依赖关系，使它们能按正确的顺序进行编译和加载。而这依靠的便是 ASDF 自动编译系统。\nASDF，全称 Another System Definition Facility，该构建系统指定了 Common Lisp 程序中各系统的组成及控制各组件能按正确的顺序进行编译、加载和测试等等。\n ASDF, or Another System Definition Facility, is a build system: a tool for specifying how systems of Common Lisp software are made up of components (sub-systems and files), and how to operate on these components in the right order so that they can be compiled, loaded, tested, etc.\n 这里不讨论 ASDF 的具体用法。直接看看 postmodern.asd 文件的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ;;;; -*- Mode: LISP; Syntax: Ansi-Common-Lisp; Base: 10; -*- (defpackage :postmodern-system (:use :common-lisp :asdf) (:export :*threads*)) (in-package :postmodern-system) ... (defsystem \u0026#34;postmodern\u0026#34; ... :components ((:module \u0026#34;postmodern\u0026#34; ... ))) (defsystem \u0026#34;postmodern/tests\u0026#34; ... )   第一行的作用是让 Emacs 为该文件添加正确的语法支持。\n代码首先定义了一个名为 postmodern-system 的包（package），之后 defsystem 定义的系统（system）描述了对应项目的代码结构。\ndefsystem 宏的两个主要的选项中，\n :depends-on 指定该项目依赖的其他 ASDF 格式的项目， :components 定义了有依赖关系的源代码文件。  要注意的是，系统定义文件（system definition file）名与系统名（由 defsystem 定义）必须保持一致。如要同时定义其他系统，系统名需要使用前缀 \u0026lt;system-name\u0026gt;/。\n在该项目中，postmodern.asd 文件对应的系统是 postmodern，额外的系统 postmodern/tests 使用的前缀是 postmodern/。\n看下 postmodern/ 目录中 package.lisp 的内容，可以发现该文件专门定义包，并且这个包存放的是实际的逻辑代码。\n现在再看其他的文件或目录，代码结构都是类似的，理解起来并不难。\n至此，我们已经了解了 Common Lisp 项目的代码结构是怎样组织的。相比 Python 来说，多了一些东西，但学习之后，并没有什么难以理解的地方。\n想要了解 ASDF 的具体的用法，可以查阅 ASDF Manual。\n","description":"","id":4,"section":"posts","tags":["Common Lisp"],"title":"Common Lisp 项目的代码结构","uri":"http://rrcgat.github.io/en/posts/common-lisp-project-structure/"},{"content":"Common Lisp 判断对象是否相等的函数比较多，这里记录一下目前遇到的用于判断相等的函数。\n相等性判断函数 = 函数 = 用于判断数值（numbers）是否相等（不判断类型），并且只能用于判断数值类型的元素。\n语法：\n1 2 3  ;;; = \u0026amp;rest numbers+ =\u0026gt; generalized-boolean (= 1 1.0 #c(1 0)) ; =\u0026gt; T   CHAR= / STRING= char= 用于判断多个字符是否相等，区分大小写。此外，不同实现中如果定义两个字符不同，char= 返回 NIL。\n If two characters differ in any implementation-defined attributes, then they are not char=.\n 语法：\n1 2 3  ;;; char= \u0026amp;rest characters+ =\u0026gt; generalized-boolean (char= #\\d #\\d) ; =\u0026gt; T   string= 用于判断多个字符串是否相等，区分大小写。\n语法：\n1 2 3  ;;; string= string1 string2 \u0026amp;key start1 end1 start2 end2 =\u0026gt; generalized-boolean (string= \u0026#34;foo\u0026#34; \u0026#34;foo\u0026#34;) ; =\u0026gt; T   可以比较两个字符串中指定的子序列。\nCHAR-EQUAL / STRING-EQUAL char-equal 用于判断字符是否相等，且忽略大小写。语法结构与 char= 相同。同样的，不同实现结果可能不同。\n \u0026hellip; might have an implementation-defined behavior for non-simple characters.\n 1  (char-equal #\\A #\\a) ; =\u0026gt; T   string-equal 与 string= 相似，但忽略了大小写。\n1  (string-equal \u0026#34;foo\u0026#34; \u0026#34;Foo\u0026#34;) ; =\u0026gt; T   EQ eq 判断两个对象是否相同。不同的实现中，数值和字符可能相同，也可能不同。两个看起来一样的列表通常也不同。\n Returns true if its arguments are the same, identical object; otherwise, returns false.\n 语法：\n1 2 3  ;;; eq x y =\u0026gt; generalized-boolean (eq \u0026#39;a \u0026#39;a) ; =\u0026gt; T   EQL 当两个对象 x 和 y 满足以下一个条件时：\n x 和 y 相同（EQ）。 两者都是数值，且值与类型相同。 两者是字符且表示相等的字符。  eql 判定 x 和 y 相等。对于浮点类型，eql 不确保值相等的浮点数一定相等，且在区分正零和负零的实现中，(eql -0.0 0.0) 返回 NIL。\nEQUAL equal 判断两个对象是否是同构的（structurally similar, or isomorphic）。\n 对于符号，相当于使用 eq。 对于数值和字符，相当于使用 eql。 对于 cons / bit-vector / string，下降为元素间使用 equal。 对于目录名（pathname），目录各自部分相同时才相同。  pathnames that are equal should be functionally equivalent.\n  其他情况，使用 eq。  EQUALP equalp 判断相等的条件比 equal 要更宽松：\n 对于字符，使用 char-equal。 对于数值，使用 =。 对于 cons / bit-vector / string / structure / hash-table，下降为对包含的元素使用 equalp 其他情况，使用 eq  TREE-EQUAL tree-equal 用于判断 cons 组成的树是否相等，test 参数指定判断谓词。\n语法：\n1 2 3 4 5  ;;; tree-equal tree-1 tree-2 \u0026amp;key test test-not =\u0026gt; generalized-boolean (let ((tree1 \u0026#39;(1 (1 2))) (tree2 \u0026#39;(1 (1 2)))) (tree-equal tree1 tree2)) ; =\u0026gt; T   总结 对于数值型对象，一般使用 = 就足够了，使用 eq 并不安全，不推荐。而字符和字符串，char= 和 string= 或 char-equal 和 string-equal 满足绝大部分使用场景了。tree-equal 用于判断树。\n其他几个函数严格性排序如下：eq \u0026gt; eql \u0026gt; equal \u0026gt; euqalp，一般情况下，我们使用 equal 就可以了，除非知道自己需要做什么。\n更多 更多细节，欢迎访问 Common Lisp HyperSpec。\n","description":"","id":5,"section":"posts","tags":["Common Lisp"],"title":"Common Lisp 中的相等性判断","uri":"http://rrcgat.github.io/en/posts/common-lisp-equality/"},{"content":"进程间通信的几种方式 参考维基百科的分类，进程间通信主要有以下几种：\n 文件（File） 信号（Signal） 套接字（Socket） Unix 域套接字（Unix domain socket） 消息队列（Message queue） 匿名管道（Anonymous pipe） 命名管道（Named pipe） 共享内存（Shared memory） 消息传递（Message passing） 内存映射文件（Memory-mapped file）  看下使用 Python 怎么实现。\n环境：Arch Linux + Python3.8\n文件 符合直觉，数据存在硬盘上，可基于文本或二进制。\n对于 pa.py\n1 2 3 4 5 6  SHARED_FILE = \u0026#39;/tmp/shared_file\u0026#39; def send(): with open(SHARED_FILE, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: f.write(\u0026#39;some data...\u0026#39;)   对于 pb.py\n1 2 3  def receive(): with open(SHARED_FILE, encoding=\u0026#39;utf-8\u0026#39;) as f: print(f.read())   为了避免竞争，数据流向是单向的，可使用两个或以上的文件进行双向通信。\n信号 通信偏向底层，且一般不用于传输数据。\nPython 中有 os.kill(pid, sig) 以及 signal 模块。\nos.kill 发送 sig 给进程 pid，一般会意外终止进程 pid。\n1 2 3 4 5  import os import signal os.kill(48523, signal.SIGKILL)   signal 模块的例子可以看 signal — Set handlers for asynchronous events 中给出的，简洁明了。\n套接字 使用 socket 模块，C/S 形式的通信。\n对于 pa.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # Echo server program import socket HOST = \u0026#39;127.0.0.1\u0026#39; PORT = 50007 def send(): with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s: s.bind((HOST, PORT)) # 绑定地址与端口 s.listen(1) # 监听的连接数 conn, addr = s.accept() with conn: print(\u0026#39;Connected by\u0026#39;, addr) while True: data = conn.recv(1024) if not data: break conn.sendall(data)   对于 pb.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # Echo client program import socket HOST = \u0026#39;127.0.0.1\u0026#39; PORT = 50007 def receive(): with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s: s.connect((HOST, PORT)) s.sendall(b\u0026#39;Hello, world\u0026#39;) data = s.recv(1024) print(\u0026#39;Received\u0026#39;, repr(data))   例子来自于官方文档中的 socket — Low-level networking interface，稍作修改。\n在 Python3.8 中，新增了 socket.create_server 函数，合并了 bind 这一步。\n对应的 socket.create_connection 函数用于创建连接。\nUnix 域套接字 Unix 域套接字不经过网络，直接在内核中通信。\n使用方法与 socket.AF_INET 或 socket.AF_INET6 相似，\n只需把对应的 socket.AF_INET 或 socket.AF_INET6 改为 socket.AF_UNIX，\n绑定或连接的地址由 (HOST, PORT) 变为本地文件，如 '/tmp/unix_socket'。\n消息队列 Python 标准库中，multiprocessing.Queue 只能用于有关系的进程中，\n而借助第三方库的 ipcqueue 或 sysv_ipc，可在独立的进程中通信。\nipcqueue 支持 POSIX 和 System V 形式的消息队列。\n看下 POSIX 标准的消息队列。\npa.py\n1 2 3 4 5 6 7 8 9  from ipcqueue import posixmq def send(): q = posixmq.Queue(\u0026#39;/foo\u0026#39;) q.put([1, \u0026#39;A\u0026#39;]) q.put([2, \u0026#39;B\u0026#39;], priority=2) # priority 参数设置优先级 q.put([3, \u0026#39;C\u0026#39;], priority=0)   pb.py\n1 2 3 4 5 6 7 8 9 10 11 12  from ipcqueue import posixmq def receive(): q = posixmq.Queue(\u0026#39;/foo\u0026#39;) print(q.get()) print(q.get()) print(q.get()) q.close() q.unlink()   而 System V 消息队列稍有不同。\npa.py\n1 2 3 4 5 6 7 8 9 10  from ipcqueue import sysvmq def send(): q = sysvmq.Queue(1) q.put([1, \u0026#39;A\u0026#39;]) q.put([2, \u0026#39;B\u0026#39;], msg_type=2) q.put([3, \u0026#39;C\u0026#39;], msg_type=2) q.put([4, \u0026#39;D\u0026#39;], msg_type=1)   pb.py\n1 2 3 4 5 6 7 8 9 10 11 12  from ipcqueue import sysvmq def receive(): q = sysvmq.Queue(1) print(q.get(msg_type=2)) # msg_type 参数设置消息类型 print(q.get()) print(q.get()) print(q.get()) q.close()   以上代码修改自 ipcqueue documentation。\n两者用法类似，但有一些不同，主要有：\n POSIX message queue 的标识符为字符，且必须以 / 开头；\n而 System V message queue 标识符为整数，且不能为负数。\n为 0 时，表示私有队列。 POSIX message queue 可以设置优先线，读取消息按 FIFO 方式来读；\nSystem V message queue 无优先级概念，但可以设置消息类型，\n并按消息类型以 FIFO 方式读取，而 POSIX message queue 不区分消息类型。  匿名管道 匿名管道用于父子进程间打开读写通道进行通信，\n在大多数 Shell 中可以使用 | 来创建。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  import os import sys def main(): r, w = os.pipe() if os.fork(): # Parent process receive data os.close(w) r = os.fdopen(r) print(\u0026#39;Parent reading\u0026#39;, r.read()) r.close() sys.exit(0) else: # Child process write data os.close(r) w = os.fdopen(w, \u0026#39;w\u0026#39;) w.write(\u0026#39;Hello, world\u0026#39;) w.close() sys.exit(0)   要双向通信，可打开两条管道。multiprocessing.Pipe 可直接支持双工管道。\n命名管道 不同于匿名管道，命名管道利用了文件系统，可用于两个无关的进程中进行通信。\npa.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import os import errno FIFO = \u0026#39;/tmp/named_pipe\u0026#39; def send(): try: os.mkfifo(FIFO) except OSError as oe: if oe.errno != errno.EEXIST: raise oe with open(FIFO, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;Hello, world\u0026#39;)   pb.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  import os FIFO = \u0026#39;/tmp/named_pipe\u0026#39; def receive(): try: os.mkfifo(FIFO) except OSError: pass with open(FIFO) as f: while True: data = f.read() if len(data): print(data) else: break   两者均是阻塞直到另一方打开，但可以使用 os.open 进行非阻塞通信。\n代码修改自 Python read named PIPE，且仅适用于 Unix 平台。\nWindows 系统需要借助 win32pipe 和 win32file，\n具体可以看 Named Pipes Communication between Python Server and Python Client on Window。\n共享内存 共享内存是可以被不同进程同时访问的内存空间，可跨不同进程通信。\nPython3.8 中新增了 multiprocessing.shared_memory 模块以支持共享内存通信，\n使用的是 System V 风格。之前提到的 sysv_ipc 也可以用于共享内存通信，同样是 System V 风格。\n官方文档中使用 Numpy 演示 multiprocessing.shared_memory。\n查看源代码，发现对象销毁会调用 self.close 关闭共享内存的访问，\n所以必须保证两个进程活着才行。\nsysv_ipc 除了消息队列和共享内存，还可使用信号量进行通信。\n消息传递  消息传递是一项在计算机上激活动作（即运行程序）的技术。\n与传统按名字调用程序的方式不同，\n消息传递使用对象模型（object model）区别常规功能与特定实现。\n被激活的程序发送一条消息，并依靠对象选择并执行对应的代码。\n使用中间层的理由基本分为两类：封装和分发。\n 以上文字翻译自 Message passing，可能不太准确。\n常见的消息传递系统有 RPC、RMI、MPI。\n以 MPI 为例子。Python 中实现包括 pyMPI、mpi4py、pypar、MYMPI 和 ScientificPython 的子模块 MPI。这里使用 mpi4py 模块。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  import numpy from mpi4py import MPI comm = MPI.COMM_WORLD rank = comm.Get_rank() rand_num = numpy.zeros(1) if rank == 1: rand_num = numpy.random.random_sample(1) print(\u0026#34;Process\u0026#34;, rank, \u0026#34;drew the number\u0026#34;, rand_num[0]) comm.Send(rand_num, dest=0) if rank == 0: print(\u0026#34;Process\u0026#34;, rank, \u0026#34;before receiving has the number\u0026#34;, rand_num[0]) comm.Recv(rand_num, source=1) print(\u0026#34;Process\u0026#34;, rank, \u0026#34;received the number\u0026#34;, rand_num[0])   将代码保存为 mpi.py，执行命令 mpiexec -n 2 python mpi.py。\n-n 选项指定进程数。同时启动一组进程，\n每个进程都有一个唯一的编号（在这是 rank），\n根据不同的编号，程序执行不同的代码。\n不同进程可以通过 Send 和 Recv 进行通信。\n代码参考自 Python MPI: Message Passing。\n内存映射文件 与共享内存类似，但将内存映射为文件。直接看看怎么用。\n这里直接使用标准库中的 mmap 模块。\npa.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  import mmap import os path = \u0026#39;/tmp/mmapfile\u0026#39; def send(): fd = os.open(path, os.O_CREAT | os.O_TRUNC | os.O_RDWR) data = b\u0026#39;Hello, world\u0026#39; os.write(fd, b\u0026#39;\\x00\u0026#39; * len(data)) mm = mmap.mmap(fd, 0) mm[:] = data   pb.py\n1 2 3 4 5 6 7 8 9 10 11  import mmap import os path = \u0026#39;/tmp/mmapfile\u0026#39; def receive(): fd = os.open(path, os.O_RDONLY) mm = mmap.mmap(fd, 0, prot=mmap.PROT_READ) print(mm[:])   文件描述符为 -1 时，表示映射匿名内存。\nWindows 有一点不同，还可直接使用 mmap.mmap(0, length, tagname)进行通信。\n更多参考 Welcome to ipcqueue’s documentation!\nSystem V IPC for Python\n细说linux IPC（十）：system V 消息队列\nmq_overview(7) - Linux man page\n","description":"","id":6,"section":"posts","tags":["Python"],"title":"Python 进程间通信","uri":"http://rrcgat.github.io/en/posts/python-icp/"},{"content":"反转链表指定部分，稍微思考一下就有了思路，几个临界点需要注意一下。\n一开始使用一个大的循环，在循环中每次判断临界值。\n这样写出来的代码不高效，也不优雅。\n之后看了 LeetCode 讨论区，发现了更好的解决办法。\nPython 中对变量平行赋值时，有个小知识点：\n There\u0026rsquo;s a special rule that if any of the left-hand-side variables \u0026ldquo;overlap\u0026rdquo;, the assignment goes left-to-right.\n 具体可看 这个。\n所以在对几个点进行变换时，必须用一个临时变量把某个变量的值保存起来再赋值。\n使用 Common Lisp 实现代码时，把列表当链表，\n现有的操作符很容易就写出简洁的代码来：\n1 2 3 4 5 6 7 8  (defun reverse-between (head m n) (push 0 head) (let ((end-node (nthcdr n head))) (setf (cdr (nthcdr (1- m) head)) (reverse (subseq head m (1+ n)))) (setf (cdr (last head)) (cdr end-node)) (cdr head)))   同样的思路，只使用 car 和 cdr 实现起来也不难：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  (defun reverse-between (head m n) (let* ((dummy (push 0 head)) (prev dummy) (curr)) (loop repeat (1- m) do (setf prev (cdr prev))) (setf curr (cdr prev)) (loop repeat (- n m -1) with p = prev do (psetf curr (cdr curr) (cdr curr) p p curr) finally (psetf (cdr prev) p (cddr prev) curr)) (cdr dummy)))   这里的 psetf 直接就是平行赋值了。\n","description":"","id":7,"section":"notes","tags":["LeetCode"],"title":"92. Reverse Linked List II","uri":"http://rrcgat.github.io/en/notes/92-reverse-linked-list-ii/"},{"content":"问题并不复杂，要求对指定信息按指定方式解码。\n假设输入是 s，求解函数是 foo，\n则 foo(s) = foo(s[0]) * foo(char[1:]) + foo(s[:2]) * foo(s[2:])。\n递归加动态规划，很容易就写出有 Bug 的代码来。\n一些特殊情况需要考虑完全，\n不然就增加了很多试错的时间。\n一开始写了个递归的版本，修修改改，最后通过了。\n但看了 StefanPochmann 的版本，\n发现并不需要这么麻烦。\n研究了一下他的思路，自己用 Common Lisp 实现了一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  (defun num-decodings (s) (let ((prev \u0026#34;\u0026#34;) (pw 0) (cw (if (string\u0026gt; s \u0026#34;0\u0026#34;) 1 0))) (loop for curr across s do (psetf pw cw prev curr cw (+ (if (char\u0026gt; curr #\\0) cw 0) (if (\u0026lt; 9 (parse-integer (format nil \u0026#34;~a~a\u0026#34; prev curr)) 27) pw 0))) finally (return cw))))   即便使用 psetf 平行赋值，代码行数也比 Python 的实现要多。\n当然，这也跟我对 Common Lisp 并不熟悉有关，\n以后再看看。\n","description":"","id":8,"section":"notes","tags":["LeetCode"],"title":"91. Decode Ways","uri":"http://rrcgat.github.io/en/notes/91-decode-ways/"},{"content":"对技术抱有热情与好奇，还需要努力。\nKeep it simple, stupid.\n","description":"","id":9,"section":"","tags":[""],"title":"About","uri":"http://rrcgat.github.io/en/about/"}]